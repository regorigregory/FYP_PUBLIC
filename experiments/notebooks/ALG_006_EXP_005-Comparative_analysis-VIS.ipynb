{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Comparative analysis on different versions of the \"Stere-omics\" algorithm</h1>\n",
    "<h2>Introduction</h2>\n",
    "<p>The next step &nbsp;from constant weight (CW) approach was decided to be the implementation of an adaptive support weight approach. The technique selected is called bilateral support weights. Experiences in this regard are discussed in this notebook in a comparative manner.</p>\n",
    "<h2>Abstract</h2>\n",
    "<p>Two variants of bilateral weights were&nbsp; introduced to the pipeline as part of the cost function. These were referred to as &ldquo;summed&rdquo; and &ldquo;product weight&rdquo; variants. As their name suggests, the summed entailed the summation of the intensity and spatial weights whereas the &ldquo;product&rdquo; expression entailed the multiplication of the two components of bilateral weights. The achieved improvement with respect to the previous increment, where CW windows were used, was 19.2%. Achieved best percentage of bad pixels (with threshold of 1 &ndash; bad4 here) was 26.8 % after introducing a truncation operation to the cost function. Horizontal structural noise and streaking artefacts were observed upon visual analysis.</p>\n",
    "<h2>Relevant theory</h2>\n",
    "<p>There have been&nbsp; countless techniques proposed for cost aggregation in the stereo matching pipeline in order to improve on matching accuracy. Perhaps the first and simplest is what Fang termed as Constant Window Aggregation (Fang <em>et al.</em>, 2012). This entails the aggregation of cost within a window (a matrix of adjacent pixels around a pixel that is &nbsp;subject to cost). This, using Fang&rsquo;s notation, can be generalised as</p>\n",
    "<table width=\"100%\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<td width=\"7%\">\n",
    "<p>&nbsp;</p>\n",
    "</td>\n",
    "<td width=\"86%\">$$C_{\\text{CW}}\\left( x,y,d \\right) = \\sum_{\\forall\\left( x^{'},y^{'} \\right)\\mathcal{\\in N}\\left( x,y \\right)}^{}{C\\left( x^{'},y^{'},d \\right)}$$</td>\n",
    "<td width=\"7%\">\n",
    "<p>(1)</p>\n",
    "</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<p>&nbsp;</p>\n",
    "<p>where <em>ùí©</em>(<em>ùë•</em><em>, </em><em>ùë¶</em>) is a set of pixels (represented by their x and y coordinates) within a support window around a pixel (P(x,y))&nbsp; each one of them having constant weight, a constant say in the outcome. This approach was employed as part of this project&rsquo;s previously conducted experiment (ALG_005_EXP_001) resulting in a 6-9% accuracy improvement compared to the results reported by Madeo et al. (2016) with regards to the scenes Teddy and Cones of the Middlebury 2003 dataset. A more challenging dataset, Middlebury 2014 was tested as well (<a href=\"ALG_005_EXP_003-PatchMatch_2014-VIS.ipynb\">ALG_005_EXP_003-PatchMatch_2014-VIS</a>) achieving an overall 46% bad pixel ratio (with the threshold of 1 pixel difference).</p>\n",
    "<p>According to Fang (2012), after CW approaches, the proposed solutions branched into two categories: Cross-Based Aggregation (CROSS) and Adaptive Weight Aggregation (AW). While both ideas seemed interesting to consider for implementation, later work (Hamzah and Ibrahim, 2016)&nbsp; suggested that Adaptive Support Weights (ASW &ndash; which is equivalent to AW in Fang&rsquo;s terminology) would perform the best (Chen, Ardabilian and Chen, 2015). &nbsp;Therefore, it was decided that an ASW method would be implemented.</p>\n",
    "<p>Here, similarly to CW, cost is aggregated for both a&nbsp; reference and a target image pixel &nbsp;for a set of neighbouring pixels, though, their weight is dynamically calculated. A variety of methods has been proposed to calculate these dynamic weights (Hosni, Bleyer and Gelautz, 2013). One main &nbsp;characteristic of these various strategies that help differentiate between these methods is whether they performed in a symmetric or asymmetric manner. While the symmetric calculates a weight for both windows (left and right), asymmetric is only concerned with the left image window&rsquo;s weights. However, Hosni et al. concludes, there was no significant nor conclusive difference in accuracy between the two strategies in their comparison.</p>\n",
    "<p>Perhaps one of the most advanced techniques to calculate adaptive weights is trilateral filtering (Chen, Ardabilian and Chen, 2015). Chen et al.&rsquo;s ASW technique was based on&nbsp; three main rules: colour, spatial distance and boundary. According to the colour rule, if the centre pixel and a pixel&nbsp; in the support window around it have similar intensities, the probability of them having the same disparities is high, therefore this pixel&rsquo;s weight in the window should be high. According to the&nbsp; spatial distance rule the greater the distance of a pixel from the centre pixel is, the lower the &nbsp;probability of them having the same disparity. The proposed boundary rule, which also happened to be the novelty in their solution,&nbsp; states that if there is a boundary (edge i.e. discontinuity)&nbsp; between two pixels then the probability of them having the same disparity is smaller. The proposed weight function was</p>\n",
    "<table width=\"100%\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<td width=\"7%\">\n",
    "<p>&nbsp;</p>\n",
    "</td>\n",
    "<td width=\"86%\">$$\n",
    "w_{\\text{tf}}(p,q) = e^{- \\frac{\\mathrm{\\Delta}C_{\\text{pq}}}{\\gamma_{c}}} + \\ e^{- \\frac{\\mathrm{\\Delta}S_{\\text{pq}}}{\\gamma_{s}}} + \\ \\sqrt{e^{- \\frac{\\mathrm{\\Delta}C_{\\text{pq}}}{\\gamma_{c}}} + \\ e^{- \\frac{\\mathrm{\\Delta}S_{\\text{pq}}}{\\gamma_{s}}} + \\ e^{- \\frac{\\mathrm{\\Delta}E_{\\text{pq}}}{\\gamma_{E}}}}\\ \n",
    "$$,</td>\n",
    "<td width=\"7%\">\n",
    "<p>(2)</p>\n",
    "</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<p>where&nbsp; q is a pixel in the support window centred around pixel p.&nbsp; &nbsp;is calculated as the Eucledian distance between the pixel intensities of p and q,&nbsp; &nbsp;is the geometric Eucledian distance between the x,y coordinates of&nbsp; p and q, while &nbsp;is a local energy model responsible for enforcing the boundary rule. The &ldquo;&rdquo; terms are arbitrary parameters used to adjust the strength of the respective constraints.&nbsp; They proposed the weight terms to be used in an asymmetric manner and as the multiplicator of the calculated cost at pixel q (See equation 3 below). Pixel &ldquo;q&rdquo; is a pixel in the support window around pixel &ldquo;p&rdquo;.</p>\n",
    "<table width=\"100%\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<td width=\"7%\">\n",
    "<p>&nbsp;</p>\n",
    "</td>\n",
    "<td width=\"86%\">\n",
    "    $$C_{d}^{A}(p) = \\sum_{q \\in w_{p}}^{}{w\\left( p,\\ q \\right) \\bullet C_{d}(q)}$$\n",
    "    </td>\n",
    "<td width=\"7%\">\n",
    "<p>(3)</p>\n",
    "</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<p>However, as a first step towards adaptive weights in this project, this was deviated from in three regards. In this alternative implementation the first key difference was that&nbsp; only the spatial and colour terms were used as part of the cost aggregation function. Secondly, instead of using the support weight (w(p,q))&nbsp; term as the multiplicator of the cost matrix within a support window , it was made part of the cost calculation. This decision was made to be able to store intermediary weight results and not have to recalculate them thus speeding up stereo correspondence. &nbsp;Thirdly, instead of the sum of&nbsp; the two&nbsp; weight terms, their product was used. This was suggested by (De-Maeztu, Villanueva and Cabeza, 2011). This proved to be more stable after initial trials &nbsp;when it comes to the attempt of finding optimal parameters for this pipeline. &nbsp;This could be formulated as</p>\n",
    "<table width=\"100%\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<td width=\"7%\">\n",
    "<p>&nbsp;</p>\n",
    "</td>\n",
    "<td width=\"86%\">\n",
    "$$C\\left( p,d \\right) = \\sum_{q \\in w_{p},\\ \\ \\ r \\in w_{d}}^{}{\\left| \\left( e^{- \\frac{\\mathrm{\\Delta}C_{\\text{pq}}}{\\gamma_{c}}}*\\ e^{- \\frac{\\mathrm{\\Delta}S_{\\text{pq}}}{\\gamma_{s}}} \\right) \\bullet I_{\\text{pq}} - \\ \\left( e^{- \\frac{\\mathrm{\\Delta}C_{\\text{dr}}}{\\gamma_{c}}}*\\ e^{- \\frac{\\mathrm{\\Delta}S_{\\text{dr}}}{\\gamma_{s}}} \\right) \\bullet I_{\\text{dr}} \\right|\\text{ }}$$,\n",
    "    </td>\n",
    "<td width=\"7%\">\n",
    "<p>(4)</p>\n",
    "</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<p>where w<sub>p</sub> and w<sub>d </sub>&nbsp;denote the support windows around the left image&rsquo;s pixel p and the right image&rsquo;s pixel d. q and r denote pixel coordinates in the support window while I stands for pixel intensity.</p>\n",
    "<p>A variant where the bilateral terms were added together ($e^{- \\frac{\\mathrm{\\Delta}C_{\\text{pq}}}{\\gamma_{c}}} + \\ e^{- \\frac{\\mathrm{\\Delta}S_{\\text{pq}}}{\\gamma_{s}}}$) was tested as well. For a more detailed discussion or bilateral terms please visit cited sources suggested at the beginning of this section. The final version of the algorithm discussed in this report included one last altercation: the truncation operation of the calculated cost, which was conducted as</p>\n",
    "<table width=\"100%\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<td width=\"86%\">\n",
    "$$C'\\left( p,d \\right) = \\ min(C\\left( p,d \\right),\\ \\gamma)$$</td>\n",
    "<td width=\"7%\">\n",
    "<p>(5)</p>\n",
    "</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<p>Where C&rsquo; is the minimum of a user defined &nbsp;term and the cost whose calculation was descried in the previous section (equation 4). This truncation operation was suggested by multiple sources for different cost functions, therefore it was thought to be justified to implement such operation (De-Maeztu, Villanueva and Cabeza, 2011; Chen, Ardabilian and Chen, 2013, 2015; Hosni, Bleyer and Gelautz, 2013).</p>\n",
    "<h2>Methodology</h2>\n",
    "<p>First, in order to mitigate the effects of ill-parameter configuration and reduce the time needed to demonstrate relevant results, the three algorithm variants were tested on the Middlebury 2003 dataset‚Äôs quarter resolution scenes in grayscale mode.  The methodology was similar to the one followed for&nbsp; <a href=\"./ALG_005_EXP_001-VIS.ipynb\">ALG_005_EXP_001</a>. However, here, first, a range of the parameters were tested with a relatively big step (20-50). Then, the ranges with the best results were tested again, but with smaller steps (5-10). This way local minimums or locations near local minimums were thought to have been found. Notebook versions of these experiments can be found at <a href=\"ALG_006_EXP_001-Bilateral_product_2003.ipynb\">ALG_006_EXP_001</a>, <a href=\"ALG_006_EXP_002-Bilateral_summed_2003.ipynb\">ALG_006_EXP_002</a>, <a href=\"./ALG_006_EXP_006-Bilateral_sum_truncated_2014-VIS.ipynb\">ALG_006_EXP_006</a>. Separate written analysis was not created for these experiments.</p>\n",
    "<p>Therefore, numerically informed by these three initial experiments, the Middlebury 2014 dataset&rsquo;s training images were tested at quarter resolution in grayscale for a set of parameters thought to be near the local minimums. For the list of parameters please see Table 1.</p>\n",
    "<p>&nbsp;</p>\n",
    "<table width=\"601\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<td width=\"145\">\n",
    "<p>Algorithm variant</p>\n",
    "</td>\n",
    "<td width=\"123\">\n",
    "<p>Alias</p>\n",
    "</td>\n",
    "<td width=\"156\">\n",
    "<p>Support window dimensions</p>\n",
    "</td>\n",
    "<td width=\"67\">\n",
    "<p>Match values</p>\n",
    "</td>\n",
    "<td width=\"67\">\n",
    "<p>&gamma;<sub>c</sub></p>\n",
    "</td>\n",
    "<td width=\"43\">\n",
    "<p>&gamma;<sub>s</sub></p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td width=\"145\">\n",
    "<p>bilateral-summed weights*</p>\n",
    "</td>\n",
    "<td width=\"123\">\n",
    "<p>trunc_plusblg</p>\n",
    "</td>\n",
    "<td width=\"156\">\n",
    "<p>5x7</p>\n",
    "</td>\n",
    "<td width=\"67\">\n",
    "<p>30, 35</p>\n",
    "</td>\n",
    "<td width=\"67\">\n",
    "<p>1</p>\n",
    "</td>\n",
    "<td width=\"43\">\n",
    "<p>5</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td width=\"145\">\n",
    "<p>bilateral-product-weights</p>\n",
    "</td>\n",
    "<td width=\"123\">\n",
    "<p>blg</p>\n",
    "</td>\n",
    "<td width=\"156\">\n",
    "<p>3x3, 3x5, 5x7, 7x3</p>\n",
    "</td>\n",
    "<td width=\"67\">\n",
    "<p>30, 40, 50</p>\n",
    "</td>\n",
    "<td width=\"67\">\n",
    "<p>8, 10, 12</p>\n",
    "</td>\n",
    "<td width=\"43\">\n",
    "<p>90</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td width=\"145\">\n",
    "<p>bilateral-summed weights</p>\n",
    "</td>\n",
    "<td width=\"123\">\n",
    "<p>plusblg</p>\n",
    "</td>\n",
    "<td width=\"156\">\n",
    "<p>3x3, 3x5, 5x7, 7x3</p>\n",
    "</td>\n",
    "<td width=\"67\">\n",
    "<p>30, 40, 45, 55</p>\n",
    "</td>\n",
    "<td width=\"67\">\n",
    "<p>1-7</p>\n",
    "</td>\n",
    "<td width=\"43\">\n",
    "<p>1,2</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td width=\"145\">\n",
    "<p>constant window</p>\n",
    "</td>\n",
    "<td width=\"123\">\n",
    "<p>bm</p>\n",
    "</td>\n",
    "<td width=\"156\">\n",
    "<p>1x1, 1x3, 1x5, 1x7, 3x1, 3x3, 3x5, 3x7, 5x1, 5x3, 7x1, 7x3, 7x5, 9x3, 9x5, 9x7, 11x3, 11x5, 13x3, 13x5, 13x7, 15x3, 15x5, 15x7, 15x9</p>\n",
    "</td>\n",
    "<td width=\"67\">\n",
    "<p>10-110 with a step of 20</p>\n",
    "</td>\n",
    "<td width=\"67\">\n",
    "<p>-</p>\n",
    "</td>\n",
    "<td width=\"43\">\n",
    "<p>-</p>\n",
    "</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<p>* This last version was only tested with a limited set of parameters informed by the previous two variants experimental outcomes. As it was near the end of the project, final tweaks were achieved by changing the gap and egap values which remained relatively constant throughout the project. The values tested were: -4, -7, -8, -9, -11, -12, -13 for gap and -1, -3, -5 for egap.</p>\n",
    "<p>Table 1: Parameter list for the last three conducted experiments (ALG_005_EXP_003, ALG_006_EXP_001, ALG_006_EXP_003-Bilateral_product_2014-VIS, ALG_006_EXP_004-Bilateral_summed_2014-VIS)</p>\n",
    "<h2>Discussion and results</h2>\n",
    "<p>Compared to the results logged&nbsp; during the experiment on constant weight windows (CW)&nbsp; (ALG_005_EXP_001) there had been a 17% increase in accuracy (best CW: 46.01%, best bilateral: 29.4%) overall when analysing bad4 results. Introduction of the truncation operation yielded an additional 2.5% reduction in erroneous pixels overall.</p>\n",
    "<p>Significant difference in terms of accuracy between the summed and product weight term methods was first thought to not exist, the difference in between best performances (26.8% ad 29.4%) was hypothesized to be on the account of more favourable parameter selection. However, this assumption was not confirmed analytically.</p>\n",
    "<p>On the other hand, when analysing how each variant performed against individual scenes, two scenes, Jadeplant and Vintage stood out with a respective rounded difference of 26% and 24%. This suggested that the summed term performed better, although the product term was not tested with gap and egap values other than the default ones used throughout this project. Therefore, the experiment in this regard was deemed as inconclusive.</p>\n",
    "<p>The greatest improvements in accuracy between the constant and bilateral weighted methods were achieved on the scenes Adirondack (29%), ArtL (27%), Jadeplant (32%), MotorcycleE (61%), PianoL (26%) and Vintage (29%). This suggested that the application of bilateral weights (especially using the &ldquo;plus termed&rdquo; version) made the algorithm more robust towards lighting and exposure variations within a scene. Additionally, scenes with large number of discontinuities (Jadeplant) improved a lot as well. This was an interesting result since this pipeline only considered pixel intensities, not gradients (which are thought to be more invariant when lighting and exposure conditions change (De-Maeztu, Villanueva and Cabeza, 2011)).&nbsp; The worst improvements were observed w.r.t. the scene Playtable and PlaytableP. The reason behind this was not confirmed, though it was &nbsp;thought to be either the high amount of noise present in these scenes (streaking artefacts were observable) and the mainly diagonal orientation of edges within that scene which the algorithm was not able to interpret properly. The streaking artefacts (horizontal structural noise (Boyat and Joshi, 2015)) were observed throughout the dataset which was characterised as a symptomatic artefact of DP approaches (Scharstein and Szeliski, 2002).</p>\n",
    "<p>Near the right edges of the images, especially near discontinuities, controversial phenomenon was observed. Streaking artefacts than occluded regions (black pixels) affected the matching accuracy negatively. While the first one was previously identified as a result of ill-configured match value, occlusions reported the opposite effect (too low match value). The reason for this was unknown.</p>\n",
    "<p>The truncation values worked the best when they equalled with match.</p>\n",
    "<h2>Conclusion</h2>\n",
    "<p>The best results achieved overall were with the plus termed bilateral weighted variant after the application of truncation values. This resulted in an additional 19% improvement in accuracy measured by bad1. The greatest improvements benchmarked were achieved on scenes with a high amount of discontinuities and lighting and exposure variant ones. Horizontal structural noise and many streaking artefacts were observed upon visual analysis. The reasons were not determined, though were hypothesized as the result of noise and diagonal edges.</p>\n",
    "<h2>Summative conclusion</h2>\n",
    "<p>The application of bilateral support weights combined with a truncation operation yielded the best results overall and individually as well. When it comes to the reported results by Madeo et al. (2016) at quarter resolution images of the scenes of Middlebury 2003 in grayscale mode in nonoccluded regions there has been a 13.14% and 11.86% improvement achieved measured by the metric bad1. This outperformed said authors&rsquo; reported results in RGB as well (See Table 2 below).</p>\n",
    "<p>&nbsp;</p>\n",
    "<table width=\"444\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<td width=\"274\">\n",
    "<p>&nbsp;Algorithm</p>\n",
    "</td>\n",
    "<td width=\"76\">\n",
    "<p>Teddy</p>\n",
    "</td>\n",
    "<td width=\"95\">\n",
    "<p>Cones</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td width=\"274\">\n",
    "<p>Proposed</p>\n",
    "</td>\n",
    "<td width=\"76\">\n",
    "<p>11.27%</p>\n",
    "</td>\n",
    "<td width=\"95\">\n",
    "<p>7.18%</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td width=\"274\">\n",
    "<p>Madeo et al. (2016)</p>\n",
    "</td>\n",
    "<td width=\"76\">\n",
    "<p>24.41%</p>\n",
    "</td>\n",
    "<td width=\"95\">\n",
    "<p>19.04%</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td width=\"274\">\n",
    "<p>Madeo et al. (2016) -RGB</p>\n",
    "</td>\n",
    "<td width=\"76\">\n",
    "<p>13.9%</p>\n",
    "</td>\n",
    "<td width=\"95\">\n",
    "<p>9.6%</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td width=\"274\">\n",
    "<p>Improvement w.r.t. Madeo et al. (2016) grayscale</p>\n",
    "</td>\n",
    "<td width=\"76\">\n",
    "<p>13.14%</p>\n",
    "</td>\n",
    "<td width=\"95\">\n",
    "<p>11.86%</p>\n",
    "</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<p>&nbsp;</p>\n",
    "<p>Table 2: Comparison chart to the results reported by Madeo et al. (2016) on grayscale images at quarter resolution in non-occluded regions of the scenes of the Middlebury 2003 dataset.</p>\n",
    "<p>When it comes to the Middlebury 2014 dataset, an overall 27.7% increase in accuracy was measured by the metric bad1 compared to the baseline. However, after the last experiment, many streaking artefacts, horizontal structural noise was still observable throughout the scenes symptomatic to DP approaches. Hypothesized reason for this was noise present in scenes.</p>\n",
    "<p><img src=\"https://raw.githubusercontent.com/regorigregory/FYP_PUBLIC/master/git_assets/insert_graph.png\" alt=\"Benchmarking result at Middlebury 2014 - quater resolution, grayscale, non-occluded - bad1\" width=\"1914\" height=\"852\" /></p>\n",
    "<p>Figure 1: the performance of different versions of the algorithms developed in this project against the Middlebury 2014 dataset&rsquo;s training images at quarter resolution in grayscale mode. X-axis: Algorithm versions. Y-axis: bad1: percentage of bad pixels whose absolute difference to the ground truth is greater than one.</p>\n",
    "<p>With regards to exposure and lighting variations, though, improvements were achieved, it was certainly not to the satisfactory level.</p>\n",
    "<h1>References</h1>\n",
    "<ol>\n",
    "<li>Boyat, A. K. and Joshi, B. K. (2015) &lsquo;A Review Paper‚ÄØ: Noise Models in Digital Image Processing&rsquo;, <em>Signal &amp; Image Processing‚ÄØ: An International Journal</em>. Academy and Industry Research Collaboration Center (AIRCC), 6(2), pp. 63&ndash;75. doi: 10.5121/sipij.2015.6206.</li>\n",
    "<li>Chen, D., Ardabilian, M. and Chen, L. (2013) &lsquo;A novel trilateral filter based adaptive support weight method for stereo matching&rsquo;, in <em>BMVC 2013 - Electronic Proceedings of the British Machine Vision Conference 2013</em>. British Machine Vision Association, BMVA. doi: 10.5244/C.27.96.</li>\n",
    "<li>Chen, D., Ardabilian, M. and Chen, L. (2015) &lsquo;A fast trilateral filter-based adaptive support weight method for stereo matching&rsquo;, <em>IEEE Transactions on Circuits and Systems for Video Technology</em>. Institute of Electrical and Electronics Engineers Inc., 25(5), pp. 730&ndash;743. doi: 10.1109/TCSVT.2014.2361422.</li>\n",
    "<li>De-Maeztu, L., Villanueva, A. and Cabeza, R. (2011) &lsquo;Stereo matching using gradient similarity and locally adaptive support-weight&rsquo;, <em>Pattern Recognition Letters</em>. North-Holland, 32(13), pp. 1643&ndash;1651. doi: 10.1016/j.patrec.2011.06.027.</li>\n",
    "<li>Fang, J. <em>et al.</em> (2012) &lsquo;Accelerating cost aggregation for real-time stereo matching&rsquo;, in <em>Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS</em>, pp. 472&ndash;481. doi: 10.1109/ICPADS.2012.71.</li>\n",
    "<li>Hamzah, R. A. and Ibrahim, H. (2016) &lsquo;Literature Survey on Stereo Vision Disparity Map Algorithms&rsquo;, <em>Journal of Sensors</em>, 2016, pp. 1&ndash;23. doi: 10.1155/2016/8742920.</li>\n",
    "<li>Hosni, A., Bleyer, M. and Gelautz, M. (2013) &lsquo;Secrets of adaptive support weight techniques for local stereo matching&rsquo;, <em>Computer Vision and Image Understanding</em>. Academic Press, 117(6), pp. 620&ndash;632. doi: 10.1016/j.cviu.2013.01.007.</li>\n",
    "<li>Madeo, S. <em>et al.</em> (2016) &lsquo;An optimized stereo vision implementation for embedded systems: application to RGB and infra-red images&rsquo;, <em>Journal of Real-Time Image Processing</em>, 12(4), pp. 725&ndash;746. doi: 10.1007/s11554-014-0461-7.</li>\n",
    "<li>Scharstein, D. and Szeliski, R. (2002) &lsquo;A taxonomy and evaluation of dense two-frame stereo correspondence algorithms&rsquo;, <em>International Journal of Computer Vision</em>, 47(1&ndash;3), pp. 7&ndash;42. doi: 10.1023/A:1014573219977.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.join(\"..\", \"..\"))\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from ipywidgets import HBox, VBox, Button\n",
    "\n",
    "from components.utils import plotly_helpers as ph\n",
    "from components.utils import utils as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "available_metrix = ['abs_error',\n",
    "       'mse', 'avg', 'eucledian', 'bad1', 'bad2', 'bad4', 'bad8']\n",
    "\n",
    "metrics_selector = widgets.Dropdown(\n",
    "    options=[(m,m) for m in available_metrix],\n",
    "    description='Metric:',\n",
    "    value=\"bad4\"\n",
    ")\n",
    "\n",
    "\n",
    "nonoccluded = widgets.Dropdown(\n",
    "    options=[(\"yes\", False), (\"No\", True)],\n",
    "    description='Nonoccluded:'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please select metrics and whether occlusions are counted as errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d5a5cf3e0043f3b51262e8043df3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Metric:', index=6, options=(('abs_error', 'abs_error'), ('mse', 'mse'), (‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VBox([metrics_selector, nonoccluded])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data and building the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_results.csv\n",
    "\n",
    "selected_file = os.path.join(\"..\",\"..\", \"benchmarking\", \"MiddEval\", \"custom_log\", \"best_results.csv\")\n",
    "#selected_file = \"./fixed_csv2.csv\"\n",
    "df = ph.load_n_clean(selected_file)\n",
    "\n",
    "##Filtering to selected occlusion parameter\n",
    "\n",
    "df = df[df[\"are_occlusions_errors\"]==nonoccluded.value]\n",
    "df.sort_values(by=[\"scene\", \"match\", \"h\", \"w\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dashboard 1\n",
    "\n",
    "\n",
    "from ipywidgets import Image, Layout\n",
    "\n",
    "img_widget = Image(value=df[\"loaded_imgs\"].iloc[0], \n",
    "                   layout=Layout(height='375px', width='450px'))\n",
    "\n",
    "fig_a = ph.get_figure_widget (df, \"scene\", metrics_selector.value, \n",
    "                           \"Scene w.r.t.\"+metrics_selector.value)\n",
    "fig_b = ph.get_figure_widget (df, \"match\", \"kernel_size\", \"Kernel sizes w.r.t. match values\")\n",
    "\n",
    "\n",
    "figs = [fig_a, fig_b]\n",
    "ph.bind_hover_function(figs, img_widget, df)\n",
    "ph.bind_brush_function(figs, df)\n",
    "\n",
    "button = ph.get_reset_brush_button(figs)\n",
    "dashboard1 = VBox([button, fig_a,\n",
    "                  HBox([img_widget, fig_b])])\n",
    "\n",
    "\n",
    "### Dashboard 2\n",
    "\n",
    "df.sort_values(by=[\"experiment_id\"])\n",
    "traced_fig_1, dfs_1 = ph.get_figure_widget_traced(df, \"scene\", metrics_selector.value, \"experiment_id\")\n",
    "\n",
    "traced_fig_widget_1 = go.FigureWidget(traced_fig_1)\n",
    "\n",
    "\n",
    "\n",
    "traced_fig_1_imw_1 = Image(value=df[\"loaded_imgs\"].iloc[0], \n",
    "                   layout=Layout(height='375px', width='450px'))\n",
    "traced_fig_1_imw_2 = Image(value=df[\"loaded_gts\"].iloc[0], \n",
    "                   layout=Layout(height='375px', width='450px'))\n",
    "\n",
    "#figs, img_widget, selected_scene_df\n",
    "ph.bind_hover_function2([traced_fig_widget_1], traced_fig_1_imw_1, dfs_1, img_widget_groundtruth=traced_fig_1_imw_2)\n",
    "\n",
    "\n",
    "turn_the_lights_on = ph.get_dropdown_widget([\"On\", \"Off\"], label=\"Turn plots:\", values = [True, False])\n",
    "\n",
    "ph.bind_dropdown_switch_traces_fn(turn_the_lights_on, traced_fig_widget_1)\n",
    "\n",
    "dashboard2 = VBox([turn_the_lights_on, traced_fig_widget_1, HBox([traced_fig_1_imw_1,traced_fig_1_imw_2])])\n",
    "\n",
    "\n",
    "### Dashboard 3\n",
    "\n",
    "\n",
    "traced_fig_2, dfs_2 = ph.get_figure_widget_traced(df, \"experiment_id\", metrics_selector.value, \"scene\")\n",
    "\n",
    "traced_fig_widget_2 = go.FigureWidget(traced_fig_2)\n",
    "\n",
    "traced_fig_2_imw_1 = Image(value=df[\"loaded_imgs\"].iloc[0], \n",
    "                   layout=Layout(height='375px', width='450px'))\n",
    "traced_fig_2_imw_2 = Image(value=df[\"loaded_gts\"].iloc[0], \n",
    "                   layout=Layout(height='375px', width='450px'))\n",
    "\n",
    "\n",
    "\n",
    "#figs, img_widget, selected_scene_df\n",
    "ph.bind_hover_function2([traced_fig_widget_2], traced_fig_2_imw_1, dfs_2, img_widget_groundtruth=traced_fig_2_imw_2)\n",
    "\n",
    "turn_the_lights_on_2 = ph.get_dropdown_widget([\"On\", \"Off\"], label=\"Turn plots:\", values = [True, False])\n",
    "\n",
    "ph.bind_dropdown_switch_traces_fn(turn_the_lights_on_2, traced_fig_widget_2)\n",
    "\n",
    "\n",
    "dashboard3 = VBox([turn_the_lights_on_2, traced_fig_widget_2, HBox([traced_fig_2_imw_1,traced_fig_2_imw_2])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To aid interaction with the plots, the best results in a tabular form are displayed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>bad4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trunc_plusblg_30_5x7no_infmge_30_-9_-1_gc_5_gs_1_a_30</th>\n",
       "      <th>5x7</th>\n",
       "      <th>30</th>\n",
       "      <td>0.268293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plusblg_45_5x7gc_5_gs_1_alph_0</th>\n",
       "      <th>5x7</th>\n",
       "      <th>45</th>\n",
       "      <td>0.294960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blg_40_5x7gc_8_gs_90_alph_0</th>\n",
       "      <th>5x7</th>\n",
       "      <th>40</th>\n",
       "      <td>0.336915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm_30_9x3</th>\n",
       "      <th>9x3</th>\n",
       "      <th>30</th>\n",
       "      <td>0.460599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm_30_1x1</th>\n",
       "      <th>1x1</th>\n",
       "      <th>30</th>\n",
       "      <td>0.545460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          bad4\n",
       "experiment_id                                      kernel_size match          \n",
       "trunc_plusblg_30_5x7no_infmge_30_-9_-1_gc_5_gs_... 5x7         30     0.268293\n",
       "plusblg_45_5x7gc_5_gs_1_alph_0                     5x7         45     0.294960\n",
       "blg_40_5x7gc_8_gs_90_alph_0                        5x7         40     0.336915\n",
       "bm_30_9x3                                          9x3         30     0.460599\n",
       "bm_30_1x1                                          1x1         30     0.545460"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df, index = [\"experiment_id\", \"kernel_size\", \"match\"], values = \"bad4\", aggfunc=np.mean).sort_values(by=\"bad4\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>scene</th>\n",
       "      <th>Adirondack</th>\n",
       "      <th>ArtL</th>\n",
       "      <th>Jadeplant</th>\n",
       "      <th>Motorcycle</th>\n",
       "      <th>MotorcycleE</th>\n",
       "      <th>Piano</th>\n",
       "      <th>PianoL</th>\n",
       "      <th>Pipes</th>\n",
       "      <th>Playroom</th>\n",
       "      <th>Playtable</th>\n",
       "      <th>PlaytableP</th>\n",
       "      <th>Recycle</th>\n",
       "      <th>Shelves</th>\n",
       "      <th>Teddy</th>\n",
       "      <th>Vintage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blg_40_5x7gc_8_gs_90_alph_0</th>\n",
       "      <td>0.203030</td>\n",
       "      <td>0.232686</td>\n",
       "      <td>0.628386</td>\n",
       "      <td>0.152385</td>\n",
       "      <td>0.352644</td>\n",
       "      <td>0.352539</td>\n",
       "      <td>0.548609</td>\n",
       "      <td>0.269689</td>\n",
       "      <td>0.359628</td>\n",
       "      <td>0.361980</td>\n",
       "      <td>0.243838</td>\n",
       "      <td>0.224692</td>\n",
       "      <td>0.396556</td>\n",
       "      <td>0.114476</td>\n",
       "      <td>0.612593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm_30_1x1</th>\n",
       "      <td>0.512256</td>\n",
       "      <td>0.619496</td>\n",
       "      <td>0.643227</td>\n",
       "      <td>0.305835</td>\n",
       "      <td>0.862832</td>\n",
       "      <td>0.499068</td>\n",
       "      <td>0.800975</td>\n",
       "      <td>0.405057</td>\n",
       "      <td>0.533133</td>\n",
       "      <td>0.483722</td>\n",
       "      <td>0.458109</td>\n",
       "      <td>0.474800</td>\n",
       "      <td>0.545383</td>\n",
       "      <td>0.294317</td>\n",
       "      <td>0.743693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm_30_9x3</th>\n",
       "      <td>0.452485</td>\n",
       "      <td>0.483601</td>\n",
       "      <td>0.637492</td>\n",
       "      <td>0.177582</td>\n",
       "      <td>0.839589</td>\n",
       "      <td>0.437705</td>\n",
       "      <td>0.727591</td>\n",
       "      <td>0.306500</td>\n",
       "      <td>0.454554</td>\n",
       "      <td>0.369285</td>\n",
       "      <td>0.291468</td>\n",
       "      <td>0.396472</td>\n",
       "      <td>0.482954</td>\n",
       "      <td>0.188396</td>\n",
       "      <td>0.663315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plusblg_45_5x7gc_5_gs_1_alph_0</th>\n",
       "      <td>0.190174</td>\n",
       "      <td>0.245474</td>\n",
       "      <td>0.357256</td>\n",
       "      <td>0.152771</td>\n",
       "      <td>0.318755</td>\n",
       "      <td>0.344669</td>\n",
       "      <td>0.528892</td>\n",
       "      <td>0.262903</td>\n",
       "      <td>0.334247</td>\n",
       "      <td>0.359784</td>\n",
       "      <td>0.245759</td>\n",
       "      <td>0.204286</td>\n",
       "      <td>0.399170</td>\n",
       "      <td>0.104634</td>\n",
       "      <td>0.375619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trunc_plusblg_30_5x7no_infmge_30_-9_-1_gc_5_gs_1_a_30</th>\n",
       "      <td>0.162497</td>\n",
       "      <td>0.212571</td>\n",
       "      <td>0.313128</td>\n",
       "      <td>0.139842</td>\n",
       "      <td>0.227339</td>\n",
       "      <td>0.303526</td>\n",
       "      <td>0.467895</td>\n",
       "      <td>0.206119</td>\n",
       "      <td>0.300056</td>\n",
       "      <td>0.375146</td>\n",
       "      <td>0.250492</td>\n",
       "      <td>0.177198</td>\n",
       "      <td>0.413843</td>\n",
       "      <td>0.093185</td>\n",
       "      <td>0.381559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "scene                                               Adirondack      ArtL  \\\n",
       "experiment_id                                                              \n",
       "blg_40_5x7gc_8_gs_90_alph_0                           0.203030  0.232686   \n",
       "bm_30_1x1                                             0.512256  0.619496   \n",
       "bm_30_9x3                                             0.452485  0.483601   \n",
       "plusblg_45_5x7gc_5_gs_1_alph_0                        0.190174  0.245474   \n",
       "trunc_plusblg_30_5x7no_infmge_30_-9_-1_gc_5_gs_...    0.162497  0.212571   \n",
       "\n",
       "scene                                               Jadeplant  Motorcycle  \\\n",
       "experiment_id                                                               \n",
       "blg_40_5x7gc_8_gs_90_alph_0                          0.628386    0.152385   \n",
       "bm_30_1x1                                            0.643227    0.305835   \n",
       "bm_30_9x3                                            0.637492    0.177582   \n",
       "plusblg_45_5x7gc_5_gs_1_alph_0                       0.357256    0.152771   \n",
       "trunc_plusblg_30_5x7no_infmge_30_-9_-1_gc_5_gs_...   0.313128    0.139842   \n",
       "\n",
       "scene                                               MotorcycleE     Piano  \\\n",
       "experiment_id                                                               \n",
       "blg_40_5x7gc_8_gs_90_alph_0                            0.352644  0.352539   \n",
       "bm_30_1x1                                              0.862832  0.499068   \n",
       "bm_30_9x3                                              0.839589  0.437705   \n",
       "plusblg_45_5x7gc_5_gs_1_alph_0                         0.318755  0.344669   \n",
       "trunc_plusblg_30_5x7no_infmge_30_-9_-1_gc_5_gs_...     0.227339  0.303526   \n",
       "\n",
       "scene                                                 PianoL     Pipes  \\\n",
       "experiment_id                                                            \n",
       "blg_40_5x7gc_8_gs_90_alph_0                         0.548609  0.269689   \n",
       "bm_30_1x1                                           0.800975  0.405057   \n",
       "bm_30_9x3                                           0.727591  0.306500   \n",
       "plusblg_45_5x7gc_5_gs_1_alph_0                      0.528892  0.262903   \n",
       "trunc_plusblg_30_5x7no_infmge_30_-9_-1_gc_5_gs_...  0.467895  0.206119   \n",
       "\n",
       "scene                                               Playroom  Playtable  \\\n",
       "experiment_id                                                             \n",
       "blg_40_5x7gc_8_gs_90_alph_0                         0.359628   0.361980   \n",
       "bm_30_1x1                                           0.533133   0.483722   \n",
       "bm_30_9x3                                           0.454554   0.369285   \n",
       "plusblg_45_5x7gc_5_gs_1_alph_0                      0.334247   0.359784   \n",
       "trunc_plusblg_30_5x7no_infmge_30_-9_-1_gc_5_gs_...  0.300056   0.375146   \n",
       "\n",
       "scene                                               PlaytableP   Recycle  \\\n",
       "experiment_id                                                              \n",
       "blg_40_5x7gc_8_gs_90_alph_0                           0.243838  0.224692   \n",
       "bm_30_1x1                                             0.458109  0.474800   \n",
       "bm_30_9x3                                             0.291468  0.396472   \n",
       "plusblg_45_5x7gc_5_gs_1_alph_0                        0.245759  0.204286   \n",
       "trunc_plusblg_30_5x7no_infmge_30_-9_-1_gc_5_gs_...    0.250492  0.177198   \n",
       "\n",
       "scene                                                Shelves     Teddy  \\\n",
       "experiment_id                                                            \n",
       "blg_40_5x7gc_8_gs_90_alph_0                         0.396556  0.114476   \n",
       "bm_30_1x1                                           0.545383  0.294317   \n",
       "bm_30_9x3                                           0.482954  0.188396   \n",
       "plusblg_45_5x7gc_5_gs_1_alph_0                      0.399170  0.104634   \n",
       "trunc_plusblg_30_5x7no_infmge_30_-9_-1_gc_5_gs_...  0.413843  0.093185   \n",
       "\n",
       "scene                                                Vintage  \n",
       "experiment_id                                                 \n",
       "blg_40_5x7gc_8_gs_90_alph_0                         0.612593  \n",
       "bm_30_1x1                                           0.743693  \n",
       "bm_30_9x3                                           0.663315  \n",
       "plusblg_45_5x7gc_5_gs_1_alph_0                      0.375619  \n",
       "trunc_plusblg_30_5x7no_infmge_30_-9_-1_gc_5_gs_...  0.381559  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(index = \"experiment_id\", columns=\"scene\", values = \"bad4\", aggfunc=np.min).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard 1: Scene w.r.t. {metric} (selection plot)\n",
    "<ol>\n",
    "    <li>The following figure allows to use the \"lasso\" tool as a tool of selection.</li>\n",
    "    <li>As a result, the relevant datapoints and their corresponding values in the figure in the bottom right corner will be highlighted.</li>\n",
    "    <li>Pressing the \"clear selection\" button will reset the figure.</li>\n",
    "    <li> Additionally, if a data point is hovered, the corresponding disparity output value will be displayed in the bottom right corner.</li>\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9378e64c07954c6dac3b534ca2d2b3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='clear selection', style=ButtonStyle()), FigureWidget({\n",
       "    'data': [{'custo‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dashboard1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard 2: Scenes w.r.t. {metric} with color coded \"epochs\"\n",
    "An \"epoch\" in this context means an experiment with the same settings evaluated across every scene in the Middlebury 2004 training dataset.<br>\n",
    "<ol>\n",
    "    <li>The following figure allows to turn all the plots on and off</li>\n",
    "    <li>Additionally, their visibiliy can also be handled by interacting with their legend entries on the right side of the plot.\n",
    "    </li>\n",
    "    <li> Therefore custom comparison can be made between different scenes, kernel sizes and match values. </li>\n",
    "    <li> The figure in the bottom left corner shows the corresponding disparity map. </li>\n",
    "    <li> The figure in the bottom right corner shows the corresponding ground truth disparity map. </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99503d3322a444c2a5a4a45611fe52c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Turn plots:', options=(('On', True), ('Off', False)), value=True), Figure‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dashboard2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard 3: \"Epoch\" w.r.t. {metric} with color coded scenes\n",
    "An \"epoch\" in this context means an experiment with the same settings evaluated across every scene in the Middlebury 2004 training dataset.<br>\n",
    "<ol>\n",
    "    <li>The following figure allows to turn all the plots on and off</li>\n",
    "    <li>Additionally, their visibiliy can also be handled by interacting with their legend entries on the right side of the plot.\n",
    "    </li>\n",
    "    <li> Therefore custom comparison can be made between different scenes, kernel sizes and match values. </li>\n",
    "    <li> The figure in the bottom left corner shows the corresponding disparity map. </li>\n",
    "    <li> The figure in the bottom right corner shows the corresponding ground truth disparity map. </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c7e65c0e7d473b8006dd4402d7514e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Turn plots:', options=(('On', True), ('Off', False)), value=True), Figure‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dashboard3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
